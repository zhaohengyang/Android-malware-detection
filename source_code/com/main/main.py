'''
@author: zhaohengyang
This package is build aiming to implement the novel method in android malware detection. For detail methodology please check the 
paper locate in https://github.com/zhaohengyang/Android-malware-detection/blob/master/CAPIL/component-api-linkage.pdf)

The code is described in the following steps:
Feature extraction from new sample set:
    We load API features from permission_API_usage table in database and extract these API features from samli source code 
    of each android application sample. We define the API usage by a distribution across four type of code locations: activity, service, provider, receiver.
    I.E. Assume an API is used in activity and service. The distribution over activity, service, provider, receiver is [1,1,0,0]
    The feature value is a value from 0 to 15 mapped from this distribution: feature = activity*1 + service*2 + provider*4 + receiver*8
    In the previous example: the distribution of [1,1,0,0] is mapped into 1*1 + 1*2 + 0*4 + 0*8 = 3
    API features extracted from one sample is a list of feature values separated by commas. 
    The general logic of this part of code is like the following:
    
    extractFeaturesFromSampleSet()
        # Create schema, features are API in permission_API_usage table
        createSchema()
            # get API from permission_API_usage table
            getDistinctAPIList()
        # mark each API usage
        processSamplesCheckingRuntime()
                # update type of each class in the sample and methods in that class
                mark()
                # for each method that invoked in several classes, merge it's usage in each class
                proceesEachClass()
                # extract feature value for each method in the sample based on its usage 
                extractFeatureFromAPIs()
                # add one sample record to arff file
                addDataToSchema()
    

test 1 --- Feature refinement's performance test
    In feature refinement we evaluate an API feature by check its average usage difference between malware and benign sample.
    The large this difference is more helpful the API feature is in our classification task. On the other hand, API which is
    widely used in sample is more helpful and rarely used APIs. We calculate a score combined both scheme called Dissimilarity-
    AndSampleCoverage and rank API feature by this score.
    
    The process of feature refinement start by selecting the top 10 feature to generate a classification model and use feature value collection file(ARFF) for test samples
    to evaluate the performance of the the model. Then select the top 20 feature to generate a different classification model to compare
    with the first model. The number of top feature keep increasing and a model is generated. The model with the highest performance
    is picked and the associated features are selected as the refined feature set.
    
    As the number of top feature being the x axis and the performance of the model being the y axis and a graph can be generated to  
    evaluate the performance of our algorithm and related algorithms.
    
    The general logic of this part of code is like the following:
    test1_1()
        showRankingByDissimilarityAndSampleCoverage()
            printFunctionInfoOrderedByIndex)()
                # Get API with different evaluation score like dissimilarityAndSampleCoverage
                getFunctionInfo()
                    # Get a feature's value list across all the training samples, each value in the list is distributed over (0, 15)
                    distributionOfAfeature()
                    # For each value, parse it to usage:[activity, service, provider, receiver]
                    # Save the summed usage across all the training samples
                    parseFunctionValue()
                    # Use the summed usage to calculate evaluation scores like sampleCoverage, dissimilarityAndSampleCoverage
                    calculateNormalizedDissimilarity()
                    # return a list of function and corresponding evaluation scores
                    return functionInfo  
    
                # Rank API by certain score
                sort()

test 2 ---  Feature refinement's performance test: Capil on top of Infogain
    
test 3 --- accuracy test: Capil vs API(true or false) 

Use flow control to run each part of the code separately
'''

from com.weka.weka_interface import *
from com.process.process import *
from com.database.database_connection import *
import datetime
from com.decompiler.decompiler import *
from com.applicationVariables.applicationVariables import *
from com.relatedApproach.relatedApproach import *
from com.performanceTestForPaper.performanceTestForPaper import *
from com.CapilApproach.CapilApproach import *

class flowControl(): 
    # extract feature from new samples
    processNewSample = False
    test1 = True
    test2 = False
    test3 = False
    
paper = performanceTestForPaper()
approach = CapilApproach()
flow = flowControl()

# step1
if flow.processNewSample:
    approach.extractFeaturesFromSampleSet()
  

print "start:" 
 
# test 1:
# Feaure refinement test: 
# frequency difference
sameSeed = 6
if flow.test1:
    print "Current seed: " + str(sameSeed)
    print "test 1 --- Feature refinement's performance test: freq_diff vs Capil vs Infogain"
    print "start freq_diff"
    paper.test1_1(test1_frequencyDiffReport, TABLENAMES["frequencyDif"], sameSeed, 1)
      
    print "start Capil"
    # DissimilarityAndSampleCoverage 
    paper.test1_1(test1_CapilReport, TABLENAMES["DissimilarityAndSampleCoverage"], sameSeed, 1)
      
    print "start Info"
    # information gain
    paper.test1_2(test1_InfoReport, sameSeed, 1)


# test 2:
# CAPIL on top of information gain
if flow.test2:
    print "test 2 ---  Feature refinement's performance test: Capil on top of Infogain"
    for index in range(6,7):   
        open(test2_Info_Capil, 'w').close() # clear the file
        roundStr = "round start ~~~~~~~~~~~~~" + str(index)
        print(roundStr)
        reportFile = open(test2_Info_Capil, "a")
        reportFile.write(roundStr)
        paper.test2(test2_Info_Capil, index, 1)
 


# test 3: 
# Result across different algorithms 
# write title
if flow.test3:
    print "test 3 --- accuracy test: Capil vs API(true or false)  "
    test3_acc_file = open(test3_acc, 'w')
    test3_AUR_file = open(test3_AUR, 'w')
    test3_acc_file.write("Aname,SVM,J48,Nearest_Neighbor,DecisionTable\n")
    test3_AUR_file.write("Aname,SVM,J48,Nearest_Neighbor,DecisionTable\n")
        
    print "start 3_1 CAPIL"
    test3_acc_file = open(test3_acc, 'a')
    test3_AUR_file = open(test3_AUR, 'a')
    test3_acc_file.write("CAPIL,")
    test3_AUR_file.write("CAPIL,")
    test3_acc_file.close()
    test3_AUR_file.close()
    paper.test3_1(wholeSetArffFilePath, sameSeed, 1, test3_acc, test3_AUR)
     
    # Related paper (true and false)
    print "start 3_2 API based approach(true and false)"
    test3_acc_file = open(test3_acc, 'a')
    test3_acc_file.write("API\ based\ approach,")
    test3_acc_file.close()
    test3_AUR_file = open(test3_AUR, 'a')
    test3_acc_file.write("API\ based\ approach,")
    test3_AUR_file.close()
    api_based_approach = API_based_approach()
    api_based_approach.generateArffFromCapil(wholeSetArffFilePath,API_based_WholeSetArffFilePath)
    paper.test3_2(API_based_WholeSetArffFilePath, sameSeed, 1, test3_acc, test3_AUR)
      
    print "start 3_3 permission based approach(true and false)"
    test3_acc_file = open(test3_acc, 'a')
    test3_AUR_file.write("Permission\ based\ approach,")
    test3_acc_file.close()
    test3_AUR_file = open(test3_AUR, 'a')
    test3_AUR_file.write("Permission\ based\ approach,")
    test3_AUR_file.close()
    permission_based_approach = Permission_based_approach(permission_based_WholeSetArffFilePath, permission_based_additionalArffFilePath)
    #permission_based_approach.generateArff_add_sample()
    paper.test3_2(permission_based_WholeSetArffFilePath, sameSeed, 1, test3_acc, test3_AUR)
      
    print "start 3_temp CAPIL"
    paper.test3_temp(wholeSetArffFilePath, sameSeed, 1)
    print "additional sample extraction 3_3 permission"
    
print "done~~~"

