'''
@author: zhaohengyang
Copyright (c) 2015 zhaohengyang. All rights reserved.

This package is build aiming to implement the novel method in android malware detection. please check our research paper
 in component-api-linkage.pdf for detail.

The code is described in the following steps:
Feature extraction from new sample set:
    We extract API feature from sample's samli source code. The feature value are 0-15 indicating where the API is used
    in source code. For detailed information pleace check "chapter 4.1 Feature extraction" in our research paper.
    (Our collected feature names are stored in permission_API_usage table in database)

    The general logic of feature extraction is the following:
    
    extractFeaturesFromSampleSet()
        # Create schema, features are API in permission_API_usage table
        createSchema()
            # get API from permission_API_usage table
            getDistinctAPIList()
        # mark each API usage
        processSamplesCheckingRuntime()
                # update type of each class in the sample and methods in that class
                mark()
                # for each method that invoked in several classes, merge it's usage in each class
                proceesEachClass()
                # extract feature value for each method in the sample based on its usage 
                extractFeatureFromAPIs()
                # add one sample record to arff file
                addDataToSchema()
    

test 1 --- Testing our Feature refinement's performance in comparison with recent research and widely used information gain algorithm

    Idea of our feature refinement algorithm:
        Sample coverage score: API which is widely used in sample is generally more helpful than rarely used APIs.
        Dissimilarity score: For API that used in one location when they are used benign applications and the other location
            for malicious applications, the distribution of the API usage across 0-15 locations for two different class tends to
            be separable. On the other hand, if an API that used in similar location for benign and malicious application, the
            distribution for two class tends to overlap. Dissimilarity score is a measurement of this usage difference.

        We combined both score called DissimilarityAndSampleCoverage and rank API feature by this score.

    Previous research (Aafer et al., 2013).
        Frequency difference score: API which is more frequently used in one type of class and less frequently used in the other has
            better score than equal frequent used in both type of classes.

    The process of feature refinement start by selecting the top 10 feature to generate a classification model and use
    feature value collection file(ARFF) for test samples to evaluate the performance of the the model. Then select the
    top 20 feature to generate a different classification model to compare with the first model. The number of top feature
    keep increasing and a model is generated. The model with the highest performance is picked and the associated features
     are selected as the refined feature set.
    
    As the number of top feature being the x axis and the performance of the model being the y axis and a graph can be generated to  
    evaluate the performance of our algorithm and related algorithms.


test 2 ---  Feature refinement's performance test: Capil on top of Infogain
    In this experiment, we try to run information gain feature select first and run capil feature selection algorithm on top of
the selected features expecting for a slightly increased performance.

test 3 --- accuracy test: Capil vs API based model
    In this experiment, we compare the performance of our model with API based approach and permission based approach on several
    classification algorithms: J48 (Decision Tree), Nearest Neighbor and Decision Table.
    The output table is used generate a line graph: Figure 3 in the paper


Use flow control to run each part of the code separately
'''


from com.relatedApproach.relatedApproach import *
from com.performanceTestForPaper.performanceTestForPaper import *
from com.CapilApproach.CapilApproach import *

class flowControl(): 
    # extract feature from new samples
    processNewSample = False
    test1 = False
    test2 = False
    test3 = True
    
paper = performanceTestForPaper()
approach = CapilApproach()
flow = flowControl()

# step1
if flow.processNewSample:
    approach.extractFeaturesFromSampleSet()
  

print "start:" 
 
# test 1:
# Feaure refinement test: 
# frequency difference
sameSeed = 6
if flow.test1:
    print "Current seed: " + str(sameSeed)
    print "test 1 --- Feature refinement's performance test: freq_diff vs Capil vs Infogain"
    print "start freq_diff"
    paper.test1_1(test1_frequencyDiffReport, TABLENAMES["frequencyDif"], sameSeed, 1)
      
    print "start Capil"
    # DissimilarityAndSampleCoverage 
    paper.test1_1(test1_CapilReport, TABLENAMES["DissimilarityAndSampleCoverage"], sameSeed, 1)
      
    print "start Info"
    # information gain
    paper.test1_2(test1_InfoReport, sameSeed, 1)


# test 2:
# CAPIL on top of information gain
if flow.test2:
    print "test 2 ---  Feature refinement's performance test: Capil on top of Infogain"
    for index in range(6,7):   
        open(test2_Info_Capil, 'w').close() # clear the file
        roundStr = "round start ~~~~~~~~~~~~~" + str(index)
        print(roundStr)
        reportFile = open(test2_Info_Capil, "a")
        reportFile.write(roundStr)
        paper.test2(test2_Info_Capil, index, 1)
 


# test 3: 
# Result across different algorithms 
# write title
if flow.test3:
    print "test 3 --- accuracy test: Capil vs API(true or false)  "
    test3_acc_file = open(test3_acc, 'w')
    test3_AUR_file = open(test3_AUR, 'w')
    test3_acc_file.write("Aname,SVM,J48,Nearest_Neighbor,DecisionTable\n")
    test3_AUR_file.write("Aname,SVM,J48,Nearest_Neighbor,DecisionTable\n")
        
    print "start 3_1 CAPIL"
    test3_acc_file = open(test3_acc, 'a')
    test3_AUR_file = open(test3_AUR, 'a')
    test3_acc_file.write("CAPIL,")
    test3_AUR_file.write("CAPIL,")
    test3_acc_file.close()
    test3_AUR_file.close()
    paper.test3_1(wholeSetArffFilePath, sameSeed, 1, test3_acc, test3_AUR)
     
    # Related paper (true and false)
    print "start 3_2 API based approach(true and false)"
    test3_acc_file = open(test3_acc, 'a')
    test3_acc_file.write("API\ based\ approach,")
    test3_acc_file.close()
    test3_AUR_file = open(test3_AUR, 'a')
    test3_acc_file.write("API\ based\ approach,")
    test3_AUR_file.close()
    api_based_approach = API_based_approach()
    api_based_approach.generateArffFromCapil(wholeSetArffFilePath,API_based_WholeSetArffFilePath)
    paper.test3_2(API_based_WholeSetArffFilePath, sameSeed, 1, test3_acc, test3_AUR)
      
    print "start 3_3 permission based approach(true and false)"
    test3_acc_file = open(test3_acc, 'a')
    test3_AUR_file.write("Permission\ based\ approach,")
    test3_acc_file.close()
    test3_AUR_file = open(test3_AUR, 'a')
    test3_AUR_file.write("Permission\ based\ approach,")
    test3_AUR_file.close()
    permission_based_approach = Permission_based_approach(permission_based_WholeSetArffFilePath, permission_based_additionalArffFilePath)
    #permission_based_approach.generateArff_add_sample()
    paper.test3_2(permission_based_WholeSetArffFilePath, sameSeed, 1, test3_acc, test3_AUR)
      
    print "start 3_temp CAPIL"
    paper.test3_temp(wholeSetArffFilePath, sameSeed, 1)
    print "additional sample extraction 3_3 permission"
    
print "done~~~"

