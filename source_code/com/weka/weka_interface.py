import weka.core.jvm as jvm
from weka.core.converters import Loader,Saver
from weka.classifiers import Classifier, Evaluation
from weka.core.classes import Random
from weka.attribute_selection import ASSearch, ASEvaluation, AttributeSelection
from weka.filters import Filter
from weka.classifiers import FilteredClassifier
from com.database.database_connection import *
from weka.filters import Filter
from com.decisionTree.DecisionTree import *
from com.feature.featureTable import *
from com.algorithms import *
import re
import sys
    
import logging
from __builtin__ import True
jvm_logger = logging.getLogger('weka.core.jvm')
jvm_logger.setLevel(logging.CRITICAL)
javabridge_logger = logging.getLogger('javabridge')
javabridge_logger.setLevel(logging.CRITICAL)

#tool funcitons
def isint(x):
    try:
        a = float(x)
        b = int(a)
    except ValueError:
        return False
    else:
        return a == b
    
def formatFeatureValue(valueStr):
    if not isint(valueStr):
        return "'" + valueStr + "'"
    else:
        return valueStr

class WekaInterface():
    def __init__(self):
        #start JVM
        jvm.start(class_path=['../workspace/libs/python-weka-wrapper.jar', '../workspace/libs/weka.jar', '../workspace/libs/classAssociationRules.jar', '../workspace/libs/conjunctiveRule.jar'],max_heap_size="1024m")

        
    def load_Arff(self, inputPath):
                
        #Loading input file
        #print inputPath
        loader = Loader(classname="weka.core.converters.ArffLoader")
        data = loader.load_file(inputPath)
        
        
        return data
    
    def save_Arff(self, data, outputPath):
        saver = Saver()
        saver.save_file(data, outputPath)
    
    
    
    def createTwoDatasets(self, wholeDataPath, trainingDataPercentage, trainingPath, testingPath, shuffleSeed = 43):
        wholeData = self.load_Arff(wholeDataPath)
        randomize = Filter(classname="weka.filters.unsupervised.instance.Randomize", options=["-S", str(shuffleSeed)])
        randomize.set_inputformat(wholeData)
        wholeData = randomize.filter(wholeData)
        
        removePercentage = Filter(classname="weka.filters.unsupervised.instance.RemovePercentage", options=["-P", str(trainingDataPercentage), "-V"])
        removePercentage.set_inputformat(wholeData)
        trainingData = removePercentage.filter(wholeData)
        print "instances:" + str(trainingData.num_instances())
        
        removePercentage = Filter(classname="weka.filters.unsupervised.instance.RemovePercentage", options=["-P", str(trainingDataPercentage)])
        removePercentage.set_inputformat(wholeData)
        testingData = removePercentage.filter(wholeData)
        
        print "instances:" + str(testingData.num_instances())
        
        self.save_Arff(trainingData, trainingPath)
        self.save_Arff(testingData, testingPath)
        
        
    def compareDistributionOfFunctions(self, data): 
        data.set_class_index(data.num_attributes() - 1)   # set class attribute        

        for index in range(0, data.num_attributes() - 1):
            attributeLine = str(data.get_attribute(index))
            attributeName = self.getAttributeName(attributeLine)
            self.compareDistributionOfFunction(attributeName, data)

    
    def compareDistributionOfFunction(self, functionName, data):
        dbmgr = permissionMappingManager(databasePath)
        [databaseBenignVec,databaseMalwareVec] = dbmgr.getTwoVectorOfFunction(functionName)
        [benignValueDistribution, malwareValueDistribution] = self.distributionOfAfeature(functionName, data)
        
        [benignVecFromFeature, malwareVecFromFeature] = [self.parseFunctionValue(benignValueDistribution), self.parseFunctionValue(malwareValueDistribution)]
        print functionName
        
        print [databaseBenignVec,databaseMalwareVec]
        #print [benignValueDistribution, malwareValueDistribution]
        print [benignVecFromFeature, malwareVecFromFeature]
    
    
    def getFunctionInfo(self, data):
        '''
        data: data in arrff file
        return a list of function and corresponding evaluation scores
        '''
        data.set_class_index(data.num_attributes() - 1)   # set class attribute      
        numberOfInstance = self.getNumOfInstance(data)
        functionInfo = []
        for index in range(0, data.num_attributes() - 1):
            attributeLine = str(data.get_attribute(index))
            functionName = self.getAttributeName(attributeLine)

            [benignVecFromFeature, malwareVecFromFeature] = self.getSumVectorsOfAFunction(functionName, data)
            [benignCoverage, malwareCoverage] = self.getSampleCoverage(functionName, data)
                
            # get bunch of information
            algo = Algorithms()
            sampleCoverage = benignCoverage + malwareCoverage
            frequncyDifference = algo.differenceBetweenTwoNum(benignCoverage,malwareCoverage)
            if benignCoverage == 0 and malwareCoverage == 0:
                malwareFrequnceAhead = 0
            else:
                malwareFrequnceAhead = float((benignCoverage - malwareCoverage) / (float(benignCoverage + malwareCoverage)/2) * 100 )  #( | V1 - V2 | / ((V1 + V2)/2) ) * 100 
        
                
            vectorDifferetUsagePercentage = algo.calculateNormalizedDissimilarity(benignVecFromFeature, malwareVecFromFeature)
                   
                
            dissimilarityAndSampleCoverage = vectorDifferetUsagePercentage + (float(sampleCoverage) / (float(numberOfInstance)))       
            functionInfo.append([functionName, benignVecFromFeature, malwareVecFromFeature, vectorDifferetUsagePercentage, frequncyDifference, malwareFrequnceAhead, benignCoverage, malwareCoverage, sampleCoverage, dissimilarityAndSampleCoverage])

        return functionInfo       
                
    def printFunctionInfoOrderedByIndex(self, index, data):
        '''
        data: arff weka.Instances 
        '''
        functionInfo = self.getFunctionInfo(data)
        functionInfo.sort(key=lambda tup: tup[index], reverse=True)
        
        self.printTitleOfFunctionInfo()
            
        #for function in functionInfo:            
        #    print ' '.join(('%*s' % (70, str(i)) for i in function))

        return functionInfo
        
   
    def printTitleOfFunctionInfo(self):
        title = ["fucntion Name","benignVec", "malwareVec", "vector different usage percentage", "frequency difference", "malwareFrequnceAhead", "benignCoverage", "malwareCoverage", "sampleCoverage","dissimilarityAndSampleCoverage"]
        print ' '.join(('%*s' % (70, str(i)) for i in title)) 
        
    def showRankingByVectorDifference(self, data):
        return self.printFunctionInfoOrderedByIndex( 3, data)   
    
    def showRankingByFrequencyDifference(self, data):
        return self.printFunctionInfoOrderedByIndex( 4, data) 
    
    def showRankingByMalwareFrequencyAhead(self, data):
        return self.printFunctionInfoOrderedByIndex( 5, data) 
    
    
    def showRankingByBenignSampleCoverage(self, data):
        return self.printFunctionInfoOrderedByIndex( 6, data) 
    
    def showRankingByMalwareSampleCoverage(self, data):
        return self.printFunctionInfoOrderedByIndex( 7, data) 
    
    def showRankingBySampleCoverage(self, data):
        return self.printFunctionInfoOrderedByIndex( 8, data) 
      
    def showRankingByDissimilarityAndSampleCoverage(self, data):
        return self.printFunctionInfoOrderedByIndex( 9, data) 

           
    
    '''
    def getSumVecotrsOfFunctions(self, data):
        data.set_class_index(data.num_attributes() - 1)   # set class attribute      
        
        listOfSumVectors = []
        for index in range(0, data.num_attributes() - 1):
            attributeLine = str(data.get_attribute(index))
            attributeName = self.getAttributeName(attributeLine)
            if self.isAttributeAFunction(attributeName):
                attributeName =  self.getFunctionName(attributeName)
                [benignVecFromFeature, malwareVecFromFeature] = self.getSumVectorsOfAFunction(attributeName, data)
                listOfSumVectors.append([attributeName, benignVecFromFeature, malwareVecFromFeature])
        return listOfSumVectors
    '''
    
    def getSumVectorsOfAFunction(self, functionName, data):
        [benignValueDistribution, malwareValueDistribution] = self.distributionOfAfeature(functionName, data)
        [benignVecFromFeature, malwareVecFromFeature] = [self.parseFunctionValue(benignValueDistribution), self.parseFunctionValue(malwareValueDistribution)]
        return [benignVecFromFeature, malwareVecFromFeature]
        
    def parseFunctionValue(self, distribution):
        k, v = distribution.keys(), distribution.values()
        sumVector = self.parseLevel(0)
        for i in range(len(k)):
            vector = self.parseLevel(int(k[i]))
            sumVector = [sumVector[0] + vector[0]*v[i],sumVector[1] + vector[1]*v[i],
                         sumVector[2] + vector[2]*v[i],sumVector[3] + vector[3]*v[i]]
        return sumVector
        
    def parseLevel(self, intValue):
        vector= []
        if intValue < 16:
            while(intValue > 0):
                vector.append(intValue % 2)
                intValue /= 2
        for index in range(0, 4 - len(vector)):
            vector.append(0)
        return vector
    
    def emlimitateUnusedFeature(self, trainData, testData = None):
        trainData.set_class_index(trainData.num_attributes() - 1)   # set class attribute
        featureIndex = -1       
        filteredTrainData = trainData
        filteredTestData = testData
        

        attribute_index = 0

        while attribute_index < filteredTrainData.num_attributes() - 1:
            sampleCoverage = 0
            #print attribute_index
            # check value for current feature in each instance
            for instance_index in range(0, filteredTrainData.num_instances()):
                instance = filteredTrainData.get_instance(instance_index)
                value = instance.get_value(attribute_index)
                
                if value > 0:
                    sampleCoverage += 1
            if sampleCoverage == 0:
                #print "found"
                remove = Filter(classname="weka.filters.unsupervised.attribute.Remove", options=["-R", str(attribute_index+1)]) #The index in this function start from 1
                remove.set_inputformat(filteredTrainData)
                filteredTrainData = remove.filter(filteredTrainData)  
                if filteredTestData:
                    remove = Filter(classname="weka.filters.unsupervised.attribute.Remove", options=["-R", str(attribute_index+1)]) #The index in this function start from 1
                    remove.set_inputformat(filteredTestData)
                    filteredTestData = remove.filter(filteredTestData)  
            else:
                attribute_index += 1

        return [filteredTrainData, filteredTestData]
        
    def getSampleCoverage(self, featureName, data):  
        data.set_class_index(data.num_attributes() - 1)   # set class attribute
        
        featureIndex = -1
        
        
        for index in range(0, data.num_attributes() - 1):
            attributeLine = str(data.get_attribute(index))
            attributeName = self.getAttributeName(attributeLine)

            #print "attributeName:" + str(attributeName)
            #print "featureName" + str(featureName)
            
            if featureName == attributeName:
                featureIndex = index
                
        benignCoverage = 0
        malwareCoverage = 0
        if featureIndex != -1:
            for index in range(0, data.num_instances()):
                instance = data.get_instance(index)
                value = instance.get_value(featureIndex)
                
                if value > 0:
                    classIndex = instance.get_class_index()
                    if instance.get_value(classIndex) == 0:
                        benignCoverage += 1
                    else:
                        malwareCoverage += 1
                    
        return [benignCoverage, malwareCoverage]
        
    def distributionOfAfeature(self, featureName, data):
        data.set_class_index(data.num_attributes() - 1)   # set class attribute
        
        featureIndex = -1
        for index in range(0, data.num_attributes() - 1):
            attributeLine = str(data.get_attribute(index))
            attributeName = self.getAttributeName(attributeLine)

            #print "attributeName:" + str(attributeName)
            #print "featureName" + str(featureName)
            
            if featureName == attributeName:
                featureIndex = index
        if featureIndex != -1:
            benignValueDistribution = {}
            malwareValueDistribution = {}
            for index in range(0, data.num_instances()):
                instance = data.get_instance(index)
                value = instance.get_value(featureIndex)
                
                classIndex = instance.get_class_index()
                if instance.get_value(classIndex) == 0:
                    if value not in benignValueDistribution.keys():
                        benignValueDistribution[value] = 1
                    else:
                        benignValueDistribution[value] += 1
                else:
                    if value not in malwareValueDistribution.keys():
                        malwareValueDistribution[value] = 1
                    else:
                        malwareValueDistribution[value] += 1
        
            return [benignValueDistribution, malwareValueDistribution]
        else:
            return None
    
    
    def getAttributeName(self, attributeLine):
        return attributeLine.split(" ")[1]
    
    

       
    def attributeSelector(self, data, selectNum):
        attributeSelector = Filter(classname="weka.filters.supervised.attribute.AttributeSelection",\
                         options=["-S", "weka.attributeSelection.Ranker -T -1.7976931348623157E308 -N " + str(selectNum),\
                                   "-E", "weka.attributeSelection.InfoGainAttributeEval"])

        attributeSelector.set_inputformat(data)
        data = attributeSelector.filter(data)
        
        #print  data.num_attributes() , "attributes selected: "
        #for attributeStr in data.attributes():
        #    print(attributeStr)
            
        return data
    def writeToPath(self, path, inputStr):
        if path != "":
            print "writeToPath: " + inputStr
            outputfile = open(path, "a")
            outputfile.write(inputStr)
    '''    
    def attribueSelectionBasedOnRankingInDatabase(self, trainingSet, indexInTable, databaseTable, csvFilePath, testingSet = None):
        trainingData = self.load_Arff(trainingSet)
        featureNum = trainingData.num_attributes() - 1
        
        if testingSet:
            testingData = self.load_Arff(testingSet)
        else:
            testingData = None
        
        
        outputStr = ""
        outputStr += databaseTable+","

        # select from database vector difference
        featureList3 = []
        wholefeatureList = []
        dbmgr = permissionAPIUsageTableManager(databasePath)

        for row in dbmgr.query("select * from " + databaseTable):
            featureList3.append(row[0])
            wholefeatureList.append(row[0])
        #featureList3.reverse()

        bestRemainFilterList = []
        resultList = []
        digit = len(featureList3) % 10
        
        bestAccuracy = 0
        bestData = 0
        
        classifier = self.algorithmPicker(trainingData, indexInTable)
        evaluation = self.evaluation(classifier, trainingData, testingData)
        if evaluation.percent_correct() >= bestAccuracy:
            bestAccuracy = evaluation.percent_correct()
            bestData = trainingData
            bestRemainFilterList = list(featureList3)
        print(self.algorithmTable[indexInTable] + ": " + "{:.2f}".format(evaluation.percent_correct()) + ", Feature select number:" + str(trainingData.num_attributes() - 1) + "/" + str(featureNum))
        resultList.append("{:.2f}".format(evaluation.percent_correct()))
        
        for i in range(0, digit):
            functionName = featureList3.pop().split("(")[0] + "\(\)"
            print "functionName:" + functionName
            remove = Filter(classname="weka.filters.unsupervised.attribute.RemoveByName", options=["-E", "^" + functionName + ".*$"])
            remove.set_inputformat(trainingData)
            trainingData = remove.filter(trainingData)
            if testingData:
                remove.set_inputformat(testingData)
                testingData = remove.filter(testingData)
            
            #print "i:" + str(i)
            #print "functionName:" + functionName
            #print "featureNum: " + str(filteredData.num_attributes() - 1)
        #for attributeStr in trainingData.attributes():
        #    print(attributeStr)
        self.printFunctionInfo(trainingData, trainingData.num_instances())
        
        classifier = self.algorithmPicker(trainingData, indexInTable)
        evaluation = self.evaluation(classifier, trainingData, testingData)
        if evaluation.percent_correct() >= bestAccuracy:
            bestAccuracy = evaluation.percent_correct()
            bestData = trainingData
            bestRemainFilterList = list(featureList3)
            
        print(self.algorithmTable[indexInTable] + ": " + "{:.2f}".format(evaluation.percent_correct()) + ", Feature select number:" + str(trainingData.num_attributes() - 1) + "/" + str(featureNum))
        resultList.append("{:.2f}".format(evaluation.percent_correct()))
            
        while trainingData.num_attributes() - 1 > 10:
            for i in range(0,10):
                functionName = featureList3.pop().split("(")[0] + "\(\)"
                remove = Filter(classname="weka.filters.unsupervised.attribute.RemoveByName", options=["-E", "^" + functionName + ".*$"])
                remove.set_inputformat(trainingData)
                trainingData = remove.filter(trainingData)
                if testingData:
                    remove.set_inputformat(testingData)
                    testingData = remove.filter(testingData)
                #print functionName
                #print "featureNum: " + str(filteredData.num_attributes() - 1)
                
            #for attributeStr in trainingData.attributes():
            #    print(attributeStr)
            self.printFunctionInfo(trainingData, trainingData.num_instances())
            
            classifier = self.algorithmPicker(trainingData, indexInTable)
            evaluation = self.evaluation(classifier, trainingData, testingData)
            if evaluation.percent_correct() >= bestAccuracy:
                
                bestAccuracy = evaluation.percent_correct()
                bestData = trainingData
                bestRemainFilterList = list(featureList3)
                print "update feature number:" + str(len(bestRemainFilterList))
                
            print(self.algorithmTable[indexInTable] + ": " + "{:.2f}".format(evaluation.percent_correct()) + ", Feature select number:" + str(trainingData.num_attributes() - 1) + "/" + str(featureNum))
            resultList.append("{:.2f}".format(evaluation.percent_correct()))

        resultList.reverse()
        
        fileteredfeatureList = []
        print "bestRemainFilterList number:" + str(len(bestRemainFilterList))
        print "wholefeatureList number:" + str(len(wholefeatureList))
        for item in wholefeatureList:
            if item not in bestRemainFilterList:
                fileteredfeatureList.append(item)
                
        print "update fileteredfeatureList number:" + str(len(fileteredfeatureList))
        for item in resultList:
            outputStr += item +","
        outputStr = outputStr[0:-1] + "\n"
        
        self.writeToPath(csvFilePath, outputStr)
        accuracyStr = "{:.2f}".format(bestAccuracy)
        print fileteredfeatureList
        return [accuracyStr, fileteredfeatureList]
    '''
    '''
    def getInforGainRanking(self, data):
        search = ASSearch(classname="weka.attributeSelection.Ranker", options=["-T", "-1.7976931348623157E308", "-N", "-1"])
        evaluator = ASEvaluation(classname="weka.attributeSelection.InfoGainAttributeEval")
        attsel = AttributeSelection()
        attsel.set_search(search)
        attsel.set_evaluator(evaluator)
        attsel.select_attributes(data)
        print("# attributes: " + str(attsel.get_number_attributes_selected()))
        print("attributes: " + str(attsel.get_selected_attributes()))
        print("result string:\n" + attsel.to_results_string())
    '''
        
    def attribueSelectionBasedOnRankingInDatabaseWrap(self, trainingSet, indexInTable, databaseTable, csvFilePath, testingSet = None):
        trainingData = self.load_Arff(trainingSet)
        
        if testingSet:
            testingData = self.load_Arff(testingSet)
        else:
            testingData = None
        
        return self.attribueSelectionBasedOnRankingInDatabase(trainingData, indexInTable, databaseTable, csvFilePath, testingData)
       
    def attribueSelectionBasedOnRankingInDatabase(self, trainingData, indexInTable, databaseTable, csvFilePath, testingData = None):     
        featureNum = trainingData.num_attributes() - 1
        outputStr = ""
        outputStr += databaseTable+","

        # select from database vector difference
        featureList3 = []
        wholefeatureList = []
        dbmgr = permissionMappingManager(databasePath)

        for row in dbmgr.query("select * from " + databaseTable):
            featureList3.append(row[0])
            wholefeatureList.append(row[0])
        #featureList3.reverse()
        
        bestRemainFilterList = []
        resultList = []
        digit = len(featureList3) % 10

        bestAccuracy = 0
        bestTrainingData = None
        bestTestingData = None
        bestEvaluation = None
        
        classifier = self.algorithmPicker(trainingData, indexInTable)
        evaluation = self.evaluation(classifier, trainingData, testingData)
        if evaluation.percent_correct() >= bestAccuracy:
            bestAccuracy = evaluation.percent_correct()
            bestTrainingData = trainingData
            bestTestingData = testingData
            bestRemainFilterList = list(featureList3)
            bestEvaluation = evaluation
            
        print(self.algorithmTable[indexInTable] + ": " + "{:.2f}".format(evaluation.percent_correct()) + ", Feature select number:" + str(trainingData.num_attributes() - 1) + "/" + str(featureNum))
        resultList.append("{:.2f}".format(evaluation.percent_correct()))
        
        if digit > 0:
            for i in range(0, digit):
                functionName = featureList3.pop().split("(")[0] + "\(\)"
                functionName = functionName.replace('$','\$')
                #print "functionName:" + functionName
                remove = Filter(classname="weka.filters.unsupervised.attribute.RemoveByName", options=["-E", "^" + functionName + ".*$"])
                remove.set_inputformat(trainingData)
                trainingData = remove.filter(trainingData)
                if testingData:
                    remove.set_inputformat(testingData)
                    testingData = remove.filter(testingData)
                
                #print "i:" + str(i)
                #print "functionName:" + functionName
                #print "featureNum: " + str(filteredData.num_attributes() - 1)
            #for attributeStr in trainingData.attributes():
            #    print(attributeStr)
            #self.printFunctionInfo(trainingData, trainingData.num_instances())
            
            classifier = self.algorithmPicker(trainingData, indexInTable)
            evaluation = self.evaluation(classifier, trainingData, testingData)
            if evaluation.percent_correct() >= bestAccuracy:
                bestAccuracy = evaluation.percent_correct()
                bestTrainingData = trainingData
                bestTestingData = testingData
                bestRemainFilterList = list(featureList3)
                bestEvaluation = evaluation
                
            print(self.algorithmTable[indexInTable] + ": " + "{:.2f}".format(evaluation.percent_correct()) + ", Feature select number:" + str(trainingData.num_attributes() - 1) + "/" + str(featureNum))
            resultList.append("{:.2f}".format(evaluation.percent_correct()))
            
        while trainingData.num_attributes() - 1 > 10:
            for i in range(0,10):
                functionName = featureList3.pop().split("(")[0] + "\(\)"
                functionName = functionName.replace('$','\$')
                #print "functionName:" + functionName
                remove = Filter(classname="weka.filters.unsupervised.attribute.RemoveByName", options=["-E", "^" + functionName + ".*$"])
                remove.set_inputformat(trainingData)
                trainingData = remove.filter(trainingData)
                if testingData:
                    remove.set_inputformat(testingData)
                    testingData = remove.filter(testingData)
                #print functionName
                #print "featureNum: " + str(filteredData.num_attributes() - 1)
                
            #for attributeStr in trainingData.attributes():
            #    print(attributeStr)
            
            classifier = self.algorithmPicker(trainingData, indexInTable)
            evaluation = self.evaluation(classifier, trainingData, testingData)
            if evaluation.percent_correct() >= bestAccuracy:
                
                bestAccuracy = evaluation.percent_correct()
                bestTrainingData = trainingData
                bestTestingData = testingData
                bestRemainFilterList = list(featureList3)
                bestEvaluation = evaluation
                #print "update feature number:" + str(len(bestRemainFilterList))
                
            print(self.algorithmTable[indexInTable] + ": " + "{:.2f}".format(evaluation.percent_correct()) + ", Feature select number:" + str(trainingData.num_attributes() - 1) + "/" + str(featureNum))
            resultList.append("{:.2f}".format(evaluation.percent_correct()))

        resultList.reverse()
        
        fileteredfeatureList = []
        #print "bestRemainFilterList number:" + str(len(bestRemainFilterList))
        #print "wholefeatureList number:" + str(len(wholefeatureList))
        for item in wholefeatureList:
            if item not in bestRemainFilterList:
                fileteredfeatureList.append(item)
                
        #print "update fileteredfeatureList number:" + str(len(fileteredfeatureList))
        for item in resultList:
            outputStr += item +","
        outputStr = outputStr[0:-1] + "\n"
        
        print outputStr
        self.writeToPath(csvFilePath, outputStr)
        accuracyStr = "{:.2f}".format(bestAccuracy)
        #print fileteredfeatureList
        return [bestEvaluation, bestTrainingData, bestTestingData, resultList]
    
    # dataNeedToBeFiltered have features that already removed from basedData 
    # This function aims to remove these features.
    def filterUnusedFeatureBasedOnData(self, basedData, dataNeedToBeFiltered):        
        usefulFunctionList = self.getFunctionNameListForFiltering(basedData) 
        allFunctionList = self.getFunctionNameListForFiltering(dataNeedToBeFiltered)
        unusefulFunctionList = self.getItemsNotInTheList(allFunctionList, usefulFunctionList)
        #print allFunctionList
        #print unusefulFunctionList
        filteredData = self.filterUnusedFeatureFromList(dataNeedToBeFiltered, unusefulFunctionList)
        
        return filteredData
        
    # The function in the unusedFuncitonList are formated with '\$' and "\(\)"
    def filterUnusedFeatureFromList(self, data, unusedFuncitonList):
        filteredData = data

        for attribute in unusedFuncitonList:                
            remove = Filter(classname="weka.filters.unsupervised.attribute.RemoveByName", options=["-E", "^" + attribute + ".*$"])
            remove.set_inputformat(filteredData)
            filteredData = remove.filter(filteredData)

        return filteredData      
                    
    def getFunctionNameListForFiltering(self, data):
        attributeIn = data.attributes()
        #print attributeIn
        attributeList = []
        for item in attributeIn:
            functionName = str(item).split(" ")[1]
            functionName = functionName.split("(")[0] + "\(\)"
            functionName = functionName.replace('$','\$')
            #print functionName
            attributeList.append(functionName)      
        return attributeList
            
    def writeTenScaledTitle(self, data, csvFilePath):

        featureNum = data.num_attributes() - 1
        
        csvFile = open(csvFilePath, "w")
        csvFile.write("Mname,")
        
        step = 10
        while step < featureNum:
            csvFile.write(str(step) +",")
            step += 10 
        csvFile.write(str(featureNum) + "\n")
        
    def writeTenScaledTitleManual(self, featureNum, csvFilePath):
        csvFile = open(csvFilePath, "w")
        csvFile.write("Mname,")
        
        step = 10
        while step < featureNum:
            csvFile.write(str(step) +",")
            step += 10 
        csvFile.write(str(featureNum) + "\n")
    
    def getTopFeatureInfoByInfoGain(self, trainingSet, numSelect, sampleSetSize):
        trainingData = self.load_Arff(trainingSet)
        filteredTrainData = self.attributeSelector(trainingData, numSelect)
        self.printFunctionInfo(filteredTrainData, sampleSetSize)
    

            
    def getTenScaledResultsRankedByInfo(self, trainingData, indexInTable, csvFilePath, testingData = None):
        dbmgr = permissionMappingManager(databasePath)
        featureNum = trainingData.num_attributes() - 1
        
        attributeIn = trainingData.attributes()
        attributeList = []
        for item in attributeIn:
            functionName = str(item).split(" ")[1]
            functionName = functionName.split("(")[0] + "\(\)"
            functionName = functionName.replace('$','\$')
            #print functionName
            attributeList.append(functionName)
        
        
        outputStr = ""
        outputStr += "InfomationGain" + ","
        resultList = []
        bestAccuracy = 0
        bestTrainData = 0
        bestTestData = 0
        
        #for index in range(0, len(attributeList)-1):
        #    attributeList[index] = attributeList[index].split(" ")[1]
        #    print attributeList[index]
        

        csvFile = open(csvFilePath, "a")
        csvFile.write(self.algorithmTable[indexInTable]+",") 
        
        step = 10 
        while step < featureNum:
            # pick top features
            filteredTrainData = self.attributeSelector(trainingData, step)
            
            
            # check top feature informations
            APIList = []  
            for item in filteredTrainData.attributes():
                #print str(item)
                functionName = str(item).split(" ")[1]
                #functionName = functionName.split("_")[0][1:] 
                APIList.append(functionName)
                
            numberOfInstance = self.getNumOfInstance(trainingData)
            
            
                
            # Get those features that it doesn't pick
            filteredList = []
            attributeIn = filteredTrainData.attributes()
            for item in attributeIn:
                functionName = str(item).split(" ")[1]
                functionName = functionName.split("(")[0] + "\(\)"
                functionName = functionName.replace('$','\$')
                filteredList.append(functionName)

            items = self.getItemsNotInTheList(attributeList, filteredList)
            #print len(items)
            #for item in items:
            #    print item
            # Re-process training data and make testing Data synchronized

            filteredTrainData = trainingData
            filterTestingData = testingData
            for attribute in items:                
                remove = Filter(classname="weka.filters.unsupervised.attribute.RemoveByName", options=["-E", "^" + attribute + ".*$"])

                remove.set_inputformat(filteredTrainData)
                filteredTrainData = remove.filter(filteredTrainData)
                if filterTestingData:
                    remove.set_inputformat(filterTestingData)
                    filterTestingData = remove.filter(filterTestingData)
                #print attribute
                #print str(filteredTrainData.num_attributes() - 1)

            # Build classifier and evaluate it   
            classifier = self.algorithmPicker(filteredTrainData, indexInTable)    
            evaluation = self.evaluation(classifier, filteredTrainData, filterTestingData)
            #print(self.algorithmTable[indexInTable] + ": " + "{:.2f}".format(evaluation.percent_correct()) + ", Feature select number:" + str(filteredTrainData.num_attributes() - 1) + "/" + str(featureNum))
            resultList.append("{:.2f}".format(evaluation.percent_correct()))
            
            #Save best data and accuracy
            if evaluation.percent_correct() > bestAccuracy:
                bestAccuracy = evaluation.percent_correct()
                bestTrainData = filteredTrainData
                if testingData:
                    bestTestData = filterTestingData
                #bestEvaluation = evaluation
            step += 10
            
        
        
        classifier = self.algorithmPicker(trainingData, indexInTable)
        evaluation = self.evaluation(classifier, trainingData, testingData)
        #print(self.algorithmTable[indexInTable] + ": " + "{:.2f}".format(evaluation.percent_correct()) + ", Feature select number:" + str(trainingData.num_attributes() - 1) + "/" + str(featureNum))
        resultList.append("{:.2f}".format(evaluation.percent_correct()))
        
        #Save best data and accuracy
        if evaluation.percent_correct() > bestAccuracy:
            bestAccuracy = evaluation.percent_correct()
            bestTrainData = filteredTrainData
            if testingData:
                bestTestData = filterTestingData
            #bestEvaluation = evaluation
        
        for item in resultList:
            outputStr += item +","
        outputStr = outputStr[0:-1] + "\n"
        self.writeToPath(csvFilePath, outputStr)
        return [bestAccuracy, bestTrainData, bestTestData, resultList]
      
    def evaluateResult(self, trainingData, indexInTable, testingData = None):
        featureNum = trainingData.num_attributes() - 1
        # Build classifier and evaluate it   
        classifier = self.algorithmPicker(trainingData, indexInTable)    
        evaluation = self.evaluation(classifier, trainingData, testingData)
        print(self.algorithmTable[indexInTable] + " accuracy: " + "{:.2f}".format(evaluation.percent_correct()) + ", Feature select number:" + str(trainingData.num_attributes() - 1) + "/" + str(featureNum))
        print(self.algorithmTable[indexInTable] + " AUR: " + "{:.2f}".format(evaluation.area_under_roc(1)*100))
        print(evaluation.confusion_matrix())
        return [evaluation.percent_correct(),evaluation.area_under_roc(1)*100]
               
        
    def getNumOfInstance(self, data):
        
        #print str(instances)
        #classAttribue = data.get_attribute(data.num_attributes() - 1)
        #print data.num_instances()
        return data.num_instances()
    
    
    def getItemsNotInTheList(self,list, itemsInTheList):
        itemsNotInTheList = []
        for item in list:
            if item in list and item not in itemsInTheList:
                itemsNotInTheList.append(item)
        return itemsNotInTheList
    
    def writeCompareMethodTitle(self, inputPath, csvFilePath):
        data = self.load_Arff(inputPath)
        featureNum = data.num_attributes() - 1
        
        csvFile = open(csvFilePath, "w")
        csvFile.write("Mname,")
        for index in range(0,len(self.algorithmTable)-1):
            csvFile.write(self.algorithmTable[index] + ",")
        
        csvFile.write(self.algorithmTable[-1] + "\n")
        
        
    def addMethodResultUsingInfoGain(self, inputPath, methodName, csvFilePathAccuracy, csvFilePathAUR): 
        outputStrAccuracy = ""
        outputStrAccuracy += methodName+","
        
        outputStrAUR = ""
        outputStrAUR += methodName+","
           
        for index in range(0,len(self.algorithmTable)):
            item = self.getBestResultByInfoGain(inputPath, index)
            accuracyStr = item[0]
            AUR = item[1]
            outputStrAccuracy += accuracyStr + ","
            outputStrAUR += AUR + ","
            
        outputStrAccuracy = outputStrAccuracy[0:-1] + "\n"
        outputStrAUR = outputStrAUR[0:-1] + "\n"
        self.writeToPath(csvFilePathAccuracy, outputStrAccuracy)
        self.writeToPath(csvFilePathAUR, outputStrAUR)
    
    def filterOutUnnecessaryAPIAndEvaluateOurApproach(self, ourApproahFile, apiFile, indexInTable, methodName, databaseTable, csvFilePath):
        outputStr = methodName+","
        resultList = []
        # Get whole feature set of our approach
        filteredData = self.load_Arff(ourApproahFile)
        # Use this function to get selected API feature and save the unselected api in a list
        filterOutList = self.attribueSelectionBasedOnRankingInDatabase(apiFile, indexInTable, databaseTable, "")[1]
        
        # Remove unselected API
        for functionName in filterOutList:
            functionName = functionName.split("(")[0] + "\(\)"
            functionName = functionName.replace('$','\$')
            remove = Filter(classname="weka.filters.unsupervised.attribute.RemoveByName", options=["-E", "^" + functionName + ".*$"])
            remove.set_inputformat(filteredData)
            filteredData = remove.filter(filteredData)
        featureNum = filteredData.num_attributes() - 1
        print "featureNum: " + str(featureNum)
        if csvFilePath != "":
            self.writeTenScaledTitleManual(featureNum, csvFilePath)
            #print "i:" + str(i)
            #print "functionName:" + functionName
            #print "featureNum: " + str(filteredData.num_attributes() - 1)
        for attributeStr in filteredData.attributes():
            print(attributeStr)
        # Run ten scaled generation and evaluation 
        step = 10 
        while step < featureNum:
            roundData = self.attributeSelector(filteredData, step)
            classifier = self.algorithmPicker(roundData, indexInTable)
            evaluation = self.evaluation(classifier, roundData)
            #print(self.algorithmTable[indexInTable] + ": " + "{:.2f}".format(evaluation.percent_correct()) + ", Feature select number:" + str(roundData.num_attributes() - 1) + "/" + str(featureNum))
            resultList.append("{:.2f}".format(evaluation.percent_correct()))
            #csvFile.write("{:.2f}".format(evaluation.percent_correct()) +",")
            step += 10
        
        classifier = self.algorithmPicker(filteredData, indexInTable)
        evaluation = self.evaluation(classifier, filteredData)
        #print(self.algorithmTable[indexInTable] + ": " + "{:.2f}".format(evaluation.percent_correct()) + ", Feature select number:" + str(filteredData.num_attributes() - 1) + "/" + str(featureNum))
        resultList.append("{:.2f}".format(evaluation.percent_correct()))
        
        # Write out to CSV file
        for item in resultList:
            outputStr += item +","
        outputStr = outputStr[0:-1] + "\n"
        self.writeToPath(csvFilePath, outputStr)
        
               
    def addMethodResultUsingRankingBasedOnDababase(self, inputPath, methodName, databaseTable, csvFilePath): 
        outputStr = methodName+","
        for index in range(0,len(self.algorithmTable)):
            # Get the best accuracy from ten scaled evaluation
            accuracyStr = self.attribueSelectionBasedOnRankingInDatabase(inputPath, index, databaseTable, "")[0]
            print "addMethodResultUsingRankingBasedOnDababase:" + accuracyStr
            outputStr += accuracyStr + ","
            
        outputStr = outputStr[0:-1] + "\n"    
        print "addMethodResultUsingRankingBasedOnDababase:" + outputStr
        self.writeToPath(csvFilePath, outputStr)
     
    def getBestResultByInfoGain(self, inputPath, indexInTable):
        data = self.load_Arff(inputPath)
        featureNum = data.num_attributes() - 1
        
        bestAccuracy = 0
        bestData = 0
        
   
        # Find best accuracy
        step = 10 
        while step < featureNum:
            filteredData = self.attributeSelector(data, step)
            classifier = self.algorithmPicker(filteredData, indexInTable)
            evaluation = self.evaluation(classifier, filteredData)
            if evaluation.percent_correct() > bestAccuracy:
                bestAccuracy = evaluation.percent_correct()
                bestData = filteredData
                bestEvaluation = evaluation
            print bestAccuracy
            step += 10
            
        classifier = self.algorithmPicker(data, indexInTable)
        evaluation = self.evaluation(classifier, data)
        if evaluation.percent_correct() > bestAccuracy:
                bestAccuracy = evaluation.percent_correct()
                bestData = data
                bestEvaluation = evaluation
        print bestAccuracy
        # Print best accuracy and select features
        print(self.algorithmTable[indexInTable] + ": " + str(bestAccuracy) + ", Feature select number:" + str(bestData.num_attributes() - 1) + "/" + str(featureNum))
        #for attributeStr in bestData.attributes():
        #    print(attributeStr)
        return ["{:.2f}".format(bestAccuracy), str(float(bestEvaluation.area_under_roc(1))/100.0)] 
        
       

    def algorithmPicker(self, filteredData, indexInTable):
        name = self.algorithmTable[indexInTable]
        if name == "NaiveBayes":
            return self.NaiveBayes_Classifier(filteredData)
        elif name == "SMO":
            return self.SMO_Classifier(filteredData)
        elif name == "J48":
            return self.J48_Classifier(filteredData)
        elif name == "ConjunctiveRule":
            return self.ConjunctiveRule_Classifier(filteredData)
        elif name == "Nearest_Neighbor":
            return self.Nearest_Neighbor_Classifier(filteredData)
        elif name == "DecisionTable":
            return self.DecisionTable_Classifier(filteredData)
        elif name == "MultilayerPerceptron": 
            return self.MultilayerPerceptron_Classifier(filteredData)
               
    

    
    def J48_Classifier(self, data):  
        data.set_class_index(data.num_attributes() - 1)   # set class attribute
        classifier = Classifier(classname="weka.classifiers.trees.J48", options=["-C", "0.3"])
        return classifier
    
    def NaiveBayes_Classifier(self, data):
        data.set_class_index(data.num_attributes() - 1)   # set class attribute
        classifier = Classifier(classname="weka.classifiers.bayes.NaiveBayes")
        return classifier
    
    def SMO_Classifier(self, data):
        data.set_class_index(data.num_attributes() - 1)   # set class attribute
        classifier = Classifier(classname="weka.classifiers.functions.SMO")
        return classifier
    
    def ConjunctiveRule_Classifier(self, data):
        data.set_class_index(data.num_attributes() - 1)   # set class attribute
        classifier = Classifier(classname="weka.classifiers.rules.ConjunctiveRule")
        return classifier
    
    def Nearest_Neighbor_Classifier(self, data):
        data.set_class_index(data.num_attributes() - 1)   # set class attribute
        classifier = Classifier(classname="weka.classifiers.lazy.IBk")
        return classifier
    
    def DecisionTable_Classifier(self, data):
        data.set_class_index(data.num_attributes() - 1)   # set class attribute
        classifier = Classifier(classname="weka.classifiers.rules.DecisionTable")
        return classifier
    
    def MultilayerPerceptron_Classifier(self, data):
        data.set_class_index(data.num_attributes() - 1)   # set class attribute
        classifier = Classifier(classname="weka.classifiers.functions.MultilayerPerceptron")
        return classifier
    
    def showAttributeRanking(self, data):
        search = ASSearch(classname="weka.attributeSelection.Ranker", options=["-T", "-1.7976931348623157E308", "-N", "-1"])
        evaluator = ASEvaluation(classname="weka.attributeSelection.InfoGainAttributeEval")
        attsel = AttributeSelection()
        attsel.set_search(search)
        attsel.set_evaluator(evaluator)
        attsel.select_attributes(data)
        print("# attributes: " + str(attsel.get_number_attributes_selected()))
        print("attributes: " + str(attsel.get_selected_attributes()))
        print("result string:\n" + attsel.to_results_string())
        
       
        
    # Decision Tree algorithm
    def J48_Classifier_Evaluation(self, trainingSet, testingSet = None):
        #load arff  
        trainingData = self.load_Arff(trainingSet)
        if testingSet:
            testingData = self.load_Arff(testingSet)
        else:
            testingData = None
        #show attribute ranking
        #self.showAttributeRanking(data)    
            
        #classifier
        # set class attribute
        classifier = Classifier(classname="weka.classifiers.trees.J48", options=["-C", "0.3"])
        
        #evaluation
        
        evaluation = self.evaluation(classifier, trainingData, testingData)
        
        
        
        print("Decision Tree: " + str(evaluation.percent_correct()) + " AUR:" + str(evaluation.area_under_roc(1)))
        print evaluation.confusion_matrix()
        

    def evaluation(self, classifier, trainingData, testingData = None):
        trainingData.set_class_index(trainingData.num_attributes() - 1)
        if testingData == None:
            evaluation = Evaluation(trainingData) 
                                # initialize with priors
            evaluation.crossvalidate_model(classifier, trainingData, 10, Random(42))  # 10-fold CV
            return evaluation
        else:
            print "testing data exists"
            if testingData.num_attributes() == trainingData.num_attributes():
                testingData.set_class_index(testingData.num_attributes() - 1)
                evaluation = Evaluation(trainingData)   
                
                classifier.build_classifier(trainingData)
                evaluation.test_model(classifier, testingData)
                
                #for attribute in trainingData.attributes():
                #    print "train:" + str(attribute)
                #for attribute in testingData.attributes():
                #    print "test:" + str(attribute)
                    
                    
                return evaluation
            else:
                print "testing Data doesn't have same attribute with training data"
                for attribute in trainingData.attributes():
                    print "train:" + str(attribute)
                for attribute in testingData.attributes():
                    print "test:" + str(attribute)
                

    

     
    
    def getDecisionTree(self, inputPath):   
        #load arff  
        data = self.load_Arff(inputPath)  
            
        #classifier
        data.set_class_index(data.num_attributes() - 1)   # set class attribute
        classifier = Classifier(classname="weka.classifiers.trees.J48", options=["-C", "0.3"])
        
        data.set_class_index(data.num_attributes() - 1)
        classifier.build_classifier(data)
        
        
        classifierStr = str(classifier)
        for index in range(0,data.num_instances()):
            instance = data.get_instance(index)
            #print instance
            result = classifier.distribution_for_instance(instance)
            
            #print result
        graph = classifier.graph()
        return graph
        #classifier.distribution_for_instance(inst)
       
    def parseDecisionTree(self, treeStr):
        tree = DecisionTree()
        listOfNodeStr = treeStr.split("\n")
        
        for item in listOfNodeStr[1:-2]:
            #print "item:" + item
            if item.split("\"")[0].find("->") < 0:
                #print "node:" + item
                nodeId = item.split(" ")[0]
                nodeName = item.split("\"")[1]
                #print "nodeId:" + nodeId + " nodeName:" + nodeName
                if re.search(r'^benign (.*)$', nodeName) or re.search(r'^malware (.*)$', nodeName):   # Get lead node and its result(like: 16.0/1.0)
                    resultStr = re.findall(r'\((.*)\)', nodeName)[0]
                    nodeName = nodeName.split(" ")[0]
                    #print "resultStr:" +resultStr
                    leaf = True
                    treeNode = DecisionTreeNode(nodeId, nodeName, leaf, resultStr)
                    
                else:  
                    leaf = False
                    treeNode = DecisionTreeNode(nodeId, nodeName, leaf, "")
                tree.addNode(treeNode)   
                    
            else:
                #print "condition:" + item
                firstPart = item.split(" ")[0]
                [nodeId,childNodeId] = firstPart.split("->")
                
                condition = re.findall(r'\[(.*)\]', item)[0]
                condition = re.findall(r'\"(.*)\"', condition)[0]
                
                operatorStr = condition.split(" ")[0]
                value = condition.split(" ")[1]
                
                value = formatFeatureValue(value)
                
                
                if operatorStr == "=":
                    operatorStr = "=" + operatorStr 
                
                condition = operatorStr + value
                
                #print "condition:" + condition
                
                if tree.isIdInTree(nodeId):
                    node = tree.getNodeById(nodeId)
                    node.addChildNodeId(condition, childNodeId)
                #print "nodeId,childNodeId:" + nodeId + "," + childNodeId + "condition:" + condition

        #tree.printOut()  
        return tree     
        
    def useTreeForNewApps(self, tree, inputPath):
         #load arff  
        data = self.load_Arff(inputPath)  
            
        #classifier
        data.set_class_index(data.num_attributes() - 1)   # set class attribute
        
        featureList = []
        
        #print "instance:" + str(data.get_instance(0))
        for attribute in data.attributes():
            #print str(attribute)
            featureList.append(str(attribute).split(" ")[1])
        
        # Process each instance
        for index in range(0,data.num_instances()):
            values = str(data.get_instance(index)).split(",")
            for index in range(0,len(values)):
                values[index] = formatFeatureValue(values[index])
            
            feature_dict = dict(zip(featureList, values)) 
            #print feature_dict  
            [prediction, nodesInPath, totalNum, errorNum] = tree.getPathToLeaf(feature_dict)
            
            
            print "Prediction: " + prediction
            print "History found: " + str(totalNum) + "/" + str(errorNum) + " (total found)/(error predictions)"
            print "Supporting features (feature used in tree):"
            tree.outputTreePath(nodesInPath)

    def getFunctionFeaturesArff(self, wholeSetArff, functionFeatureArff):       
        data = self.load_Arff(wholeSetArff)
        filteredData = self.getSetDataBySetIndex(data, 2)     

        saver = Saver()
        saver.save_file(filteredData, functionFeatureArff)
    
    def getSetDataBySetIndex(self, data, index):
        # cut feature set out
        featureTable = FeatureTable()
        startIndexList = featureTable.getEachSetStartIndex()
        
        start = startIndexList[index]
        end = startIndexList[index+1] - 1
        remove = Filter(classname="weka.filters.unsupervised.attribute.Remove", options=["-V", "-R", str(start) + "-" + str(end) + ",last"])
        remove.set_inputformat(data)
        filteredData = remove.filter(data)
        return filteredData
        
    def __del__(self):
        #stop JVM
        print "jvm stop"
        jvm.stop() 
          
    algorithmTable = [
                    "SMO",
                    "J48",
                      #"NaiveBayes",
                      #"ConjunctiveRule",
                    "Nearest_Neighbor",
                      "DecisionTable",
                      #"MultilayerPerceptron"
                      ]   




        
#weka = WekaInterface()


#print "InfoGain api 1 results"
#weka.writeTenScaledTitle("./compare/api_1.arff", "./compare/api_1ForR.txt")
#weka.getTenScaledResultsRankedByInfo("./compare/api_1.arff", 0, "./compare/ROutput/api_1ForR.txt")
#weka.getTenScaledResultsRankedByInfo("./compare/api_1.arff", 1, "./compare/ROutput/api_1ForR.txt")
#weka.getTenScaledResultsRankedByInfo("./compare/api_1.arff", 2, "./compare/ROutput/api_1ForR.txt")
#weka.getTenScaledResultsRankedByInfo("./compare/api_1.arff", 3, "./compare/ROutput/api_1ForR.txt")
#weka.getTenScaledResultsRankedByInfo("./compare/api_1.arff", 4, "./compare/ROutput/api_1ForR.txt")
#weka.getTenScaledResultsRankedByInfo("./compare/api_1.arff", 5, "./compare/ROutput/api_1ForR.txt")


#print "InfoGain api 2or3 results"

#weka.writeTenScaledTitle("./compare/api_2or3.arff", "./compare/api_2or3ForR.txt")
#weka.getTenScaledResultsRankedByInfo("./compare/api_2or3.arff", 0, "./compare/ROutput/api_2or3ForR.txt")
#weka.getTenScaledResultsRankedByInfo("./compare/api_2or3.arff", 1, "./compare/ROutput/api_2or3ForR.txt")
#weka.getTenScaledResultsRankedByInfo("./compare/api_2or3.arff", 2, "./compare/ROutput/api_2or3ForR.txt")
#weka.getTenScaledResultsRankedByInfo("./compare/api_2or3.arff", 3, "./compare/ROutput/api_2or3ForR.txt")
#weka.getTenScaledResultsRankedByInfo("./compare/api_2or3.arff", 4, "./compare/ROutput/api_2or3ForR.txt")
#weka.getTenScaledResultsRankedByInfo("./compare/api_2or3.arff", 5, "./compare/ROutput/api_2or3ForR.txt")

#print "compare api vector and boolean"
#weka.writeCompareMethodTitle("./compare/api_1.arff", "./compare/ROutput/compareAPIMethod.txt")
#weka.addMethodResultUsingInfoGain("./compare/api_1.arff", "vector", "./compare/ROutput/compareAPIMethod.txt")
#weka.addMethodResultUsingInfoGain("./compare/api_2or3.arff", "boolean", "./compare/ROutput/compareAPIMethod.txt")


#print "vector ranking"
#weka.writeTenScaledTitle("./compare/api_1.arff", "./compare/ROutput/vectorRank.txt")
#tableName = TABLENAMES["vectorDif"]
#weka.attribueSelectionBasedOnRankingInDatabase("./compare/api_1.arff", 0, tableName, "./compare/ROutput/vectorRank.txt")
#weka.attribueSelectionBasedOnRankingInDatabase("./compare/api_1.arff", 1, tableName,  "./compare/ROutput/vectorRank.txt")
#weka.attribueSelectionBasedOnRankingInDatabase("./compare/api_1.arff", 2, tableName,  "./compare/ROutput/vectorRank.txt")
#weka.attribueSelectionBasedOnRankingInDatabase("./compare/api_1.arff", 3, tableName,  "./compare/ROutput/vectorRank.txt")
#weka.attribueSelectionBasedOnRankingInDatabase("./compare/api_1.arff", 4, tableName,  "./compare/ROutput/vectorRank.txt")
#weka.attribueSelectionBasedOnRankingInDatabase("./compare/api_1.arff", 5, tableName,  "./compare/ROutput/vectorRank.txt")

#print "frequency ranking"
#weka.writeTenScaledTitle("./compare/api_1.arff", "./compare/ROutput/fequencyRank.txt")
#tableName = TABLENAMES["frequencyDif"]
#weka.attribueSelectionBasedOnRankingInDatabase("./compare/api_2or3.arff", 0, tableName,  "./compare/ROutput/fequencyRank.txt")
#weka.attribueSelectionBasedOnRankingInDatabase("./compare/api_2or3.arff", 1, tableName,  "./compare/ROutput/fequencyRank.txt")
#weka.attribueSelectionBasedOnRankingInDatabase("./compare/api_2or3.arff", 2, tableName,  "./compare/ROutput/fequencyRank.txt")
#weka.attribueSelectionBasedOnRankingInDatabase("./compare/api_2or3.arff", 3, tableName,  "./compare/ROutput/fequencyRank.txt")
#weka.attribueSelectionBasedOnRankingInDatabase("./compare/api_2or3.arff", 4, tableName,  "./compare/ROutput/fequencyRank.txt")
#weka.attribueSelectionBasedOnRankingInDatabase("./compare/api_2or3.arff", 5, tableName,  "./compare/ROutput/fequencyRank.txt")

#print "sample coverage ranking"
#weka.writeTenScaledTitle("./compare/api_1.arff", "./compare/ROutput/sampleCoverageRank.txt")
#tableName = TABLENAMES["sampleCoverage"]
#weka.attribueSelectionBasedOnRankingInDatabase("./compare/api_2or3.arff", 0, tableName,  "./compare/ROutput/sampleCoverageRank.txt")
#weka.attribueSelectionBasedOnRankingInDatabase("./compare/api_2or3.arff", 1, tableName,  "./compare/ROutput/sampleCoverageRank.txt")
#weka.attribueSelectionBasedOnRankingInDatabase("./compare/api_2or3.arff", 2, tableName,  "./compare/ROutput/sampleCoverageRank.txt")
#weka.attribueSelectionBasedOnRankingInDatabase("./compare/api_2or3.arff", 3, tableName,  "./compare/ROutput/sampleCoverageRank.txt")
#weka.attribueSelectionBasedOnRankingInDatabase("./compare/api_2or3.arff", 4, tableName,  "./compare/ROutput/sampleCoverageRank.txt")
#weka.attribueSelectionBasedOnRankingInDatabase("./compare/api_2or3.arff", 5, tableName,  "./compare/ROutput/sampleCoverageRank.txt")


#print "compare three API ranking"
#weka.writeCompareMethodTitle("./compare/api_1.arff", "./compare/ROutput/compareThreeAPIRanking.txt")
#weka.addMethodResultUsingRankingBasedOnDababase("./compare/api_1.arff", "dis-similirity", TABLENAMES["vectorDif"], "./compare/ROutput/compareThreeAPIRanking.txt")
#weka.addMethodResultUsingRankingBasedOnDababase("./compare/api_2or3.arff", "frequency", TABLENAMES["frequencyDif"], "./compare/ROutput/compareThreeAPIRanking.txt")
#weka.addMethodResultUsingRankingBasedOnDababase("./compare/api_2or3.arff", "sampleCoverage", TABLENAMES["sampleCoverage"], "./compare/ROutput/compareThreeAPIRanking.txt")


#print "Similarity score"
#weka.writeTenScaledTitle("./compare/api_1.arff", "./compare/ROutput/similarityRank.txt")
#tableName = TABLENAMES["vectorDif"]
#weka.attribueSelectionBasedOnReversedRankingInDatabase("./compare/api_1.arff", 0, tableName, "./compare/ROutput/similarityRank.txt")
#weka.attribueSelectionBasedOnReversedRankingInDatabase("./compare/api_1.arff", 1, tableName,  "./compare/ROutput/similarityRank.txt")
#weka.attribueSelectionBasedOnReversedRankingInDatabase("./compare/api_1.arff", 2, tableName,  "./compare/ROutput/similarityRank.txt")
#weka.attribueSelectionBasedOnReversedRankingInDatabase("./compare/api_1.arff", 3, tableName,  "./compare/ROutput/similarityRank.txt")
#weka.attribueSelectionBasedOnReversedRankingInDatabase("./compare/api_1.arff", 4, tableName,  "./compare/ROutput/similarityRank.txt")
#weka.attribueSelectionBasedOnReversedRankingInDatabase("./compare/api_1.arff", 5, tableName,  "./compare/ROutput/similarityRank.txt")

#print "sample coverage and dissimilarity score"
#weka.writeTenScaledTitle("./compare/api_1.arff", "./compare/ROutput/DissimilarityAndSampleCoverage2.txt")
#tableName = TABLENAMES["DissimilarityAndSampleCoverage"]
#weka.attribueSelectionBasedOnRankingInDatabase("./compare/api_1.arff", 0, tableName, "./compare/ROutput/DissimilarityAndSampleCoverage.txt")
#weka.attribueSelectionBasedOnRankingInDatabase("./compare/api_1.arff", 1, tableName,  "./compare/ROutput/DissimilarityAndSampleCoverage.txt")
#weka.attribueSelectionBasedOnRankingInDatabase("./compare/api_1.arff", 2, tableName,  "./compare/ROutput/DissimilarityAndSampleCoverage.txt")
#weka.attribueSelectionBasedOnRankingInDatabase("./compare/api_1.arff", 3, tableName,  "./compare/ROutput/DissimilarityAndSampleCoverage.txt")
#weka.attribueSelectionBasedOnRankingInDatabase("./compare/api_1.arff", 4, tableName,  "./compare/ROutput/DissimilarityAndSampleCoverage.txt")
#weka.attribueSelectionBasedOnRankingInDatabase("./compare/api_1.arff", 5, tableName,  "./compare/ROutput/DissimilarityAndSampleCoverage.txt")

#weka.writeTenScaledTitle("./compare/api_1.arff", "./compare/ROutput/benignSampleCoverage.txt")
#tableName = TABLENAMES["benignSampleCoverage"]
#weka.attribueSelectionBasedOnRankingInDatabase("./compare/api_1.arff", 0, tableName, "./compare/ROutput/benignSampleCoverage.txt")

#weka.writeTenScaledTitle("./compare/api_1.arff", "./compare/ROutput/malwareSampleCoverage.txt")
#tableName = TABLENAMES["malwareSampleCoverage"]
#weka.attribueSelectionBasedOnRankingInDatabase("./compare/api_1.arff", 0, tableName, "./compare/ROutput/malwareSampleCoverage.txt")


#print "sample coverage ranking numeric format"
#weka.writeTenScaledTitle("./compare/api_1.arff", "./compare/ROutput/sampleCoverageRank.txt")
#tableName = TABLENAMES["sampleCoverage"]
#weka.attribueSelectionBasedOnRankingInDatabase("./compare/api_1.arff", 0, tableName,  "./compare/ROutput/sampleCoverageRank.txt")
#weka.attribueSelectionBasedOnRankingInDatabase("./compare/api_1.arff", 1, tableName,  "./compare/ROutput/sampleCoverageRank.txt")
#weka.attribueSelectionBasedOnRankingInDatabase("./compare/api_1.arff", 2, tableName,  "./compare/ROutput/sampleCoverageRank.txt")
#weka.attribueSelectionBasedOnRankingInDatabase("./compare/api_1.arff", 3, tableName,  "./compare/ROutput/sampleCoverageRank.txt")
#weka.attribueSelectionBasedOnRankingInDatabase("./compare/api_1.arff", 4, tableName,  "./compare/ROutput/sampleCoverageRank.txt")
#weka.attribueSelectionBasedOnRankingInDatabase("./compare/api_1.arff", 5, tableName,  "./compare/ROutput/sampleCoverageRank.txt")

#print "frequency ranking"
#weka.writeTenScaledTitle("./compare/api_1.arff", "./compare/ROutput/fequencyRank.txt")
#tableName = TABLENAMES["frequencyDif"]
#weka.attribueSelectionBasedOnRankingInDatabase("./compare/api_1.arff", 0, tableName,  "./compare/ROutput/fequencyRank.txt")
#weka.attribueSelectionBasedOnRankingInDatabase("./compare/api_1.arff", 1, tableName,  "./compare/ROutput/fequencyRank.txt")
#weka.attribueSelectionBasedOnRankingInDatabase("./compare/api_1.arff", 2, tableName,  "./compare/ROutput/fequencyRank.txt")
#weka.attribueSelectionBasedOnRankingInDatabase("./compare/api_1.arff", 3, tableName,  "./compare/ROutput/fequencyRank.txt")
#weka.attribueSelectionBasedOnRankingInDatabase("./compare/api_1.arff", 4, tableName,  "./compare/ROutput/fequencyRank.txt")
#weka.attribueSelectionBasedOnRankingInDatabase("./compare/api_1.arff", 5, tableName,  "./compare/ROutput/fequencyRank.txt")



#print "our appraoch: selected API + permission + manifest + score"
#tableName = TABLENAMES["DissimilarityAndSampleCoverage"]
#weka.writeTenScaledTitle("./compare/api_1.arff", "./compare/ROutput/ourApproachWholeFeatureSet.csv")
#weka.filterOutUnnecessaryAPIAndEvaluateOurApproach("./compare/ourApproach.arff", "./compare/api_1.arff", 1, "our Approach", tableName, "./compare/ROutput/ourApproachWholeFeatureSet.csv")


#print "whole set tenscaled info gain"
#weka.writeTenScaledTitle("./compare/ourApproach.arff", "./compare/ROutput/wholeSetInfoGain.txt")
#weka.getTenScaledResultsRankedByInfo("./compare/ourApproach.arff", 0, "./compare/ROutput/wholeSetInfoGain.txt")
#weka.getTenScaledResultsRankedByInfo("./compare/ourApproach.arff", 1, "./compare/ROutput/wholeSetInfoGain.txt")

#print "group 1_2_3_4"
#weka.evaluateAlgorithms("./compare/1_2_3_4.arff")

#print "Best attribule selected from: Permission & API & protectionLevelScore & Manifest"
'''
weka.getBestResult("./compare/1_3.arff", 0)
weka.getBestResult("./compare/1_3.arff", 1)
weka.getBestResult("./compare/1_3.arff", 2)
weka.getBestResult("./compare/1_3.arff", 3)
weka.getBestResult("./compare/1_3.arff", 4)
weka.getBestResult("./compare/1_3.arff", 5)
#weka.getBestResult("./compare/1_3.arff", 6)
weka.MultilayerPerceptron_Classifier_Evaluation("./compare/1_3.arff")


weka.getBestResult("./compare/1_2_4.arff", 0)

weka.getBestResult("./compare/1_2_4.arff", 1)
weka.getBestResult("./compare/1_2_4.arff", 2)
weka.getBestResult("./compare/1_2_4.arff", 3)
weka.getBestResult("./compare/1_2_4.arff", 4)


weka.getBestResult("./compare/1_2_4.arff", 5)
#weka.getBestResult("./compare/1_2_4.arff", 6)
weka.MultilayerPerceptron_Classifier_Evaluation("./compare/1_2_4.arff")
weka.MultilayerPerceptron_Classifier_Evaluation("./compare/1_3.arff")
'''
#weka.getBestResult("./compare/1_2_4.arff", 6)
#weka.getBestResult("./compare/1_3.arff", 6)
#weka.MultilayerPerceptron_Classifier_Evaluation("./compare/1.arff")
#weka.MultilayerPerceptron_Classifier_Evaluation("./compare/2.arff")
#weka.MultilayerPerceptron_Classifier_Evaluation("./compare/3.arff")
#weka.MultilayerPerceptron_Classifier_Evaluation("./compare/4.arff")

#print "compare with related approaches"
#weka.evaluateAlgorithms("./compare/40top.arff")
#weka.evaluateAlgorithms("./compare/1.arff")
#weka.evaluateAlgorithms("./compare/3.arff")

#print "compare each group"
#weka.writeCompareMethodTitle("./compare/api_1.arff", "./compare/ROutput/compareEachGroup.txt")
#weka.addMethodResultUsingInfoGain("./compare/1.arff", "group1", "./compare/ROutput/compareEachGroup.txt")
#weka.addMethodResultUsingInfoGain("./compare/2.arff", "group2", "./compare/ROutput/compareEachGroup.txt")
#weka.addMethodResultUsingInfoGain("./compare/api_1.arff", "group3", "./compare/ROutput/compareEachGroup.txt")

#print "compare related approaches"
#weka.writeCompareMethodTitle("./compare/ourApproach.arff", "./compare/ROutput/compareRelatedApproaches.txt")
#weka.writeCompareMethodTitle("./compare/ourApproach.arff", "./compare/ROutput/compareRelatedApproachesAUR.txt")
#weka.addMethodResultUsingInfoGain("./compare/1.arff", "Permission_based_approaches", "./compare/ROutput/compareRelatedApproaches.txt", "./compare/ROutput/compareRelatedApproachesAUR.txt")
#weka.addMethodResultUsingInfoGain("./compare/3.arff", "API_based_approaches", "./compare/ROutput/compareRelatedApproaches.txt", "./compare/ROutput/compareRelatedApproachesAUR.txt")
#weka.addMethodResultUsingInfoGain("./compare/ourApproach.arff", "Our_approach", "./compare/ROutput/compareRelatedApproaches.txt", "./compare/ROutput/compareRelatedApproachesAUR.txt")

#weka.J48_Classifier_Evaluation("../workspace/results/training_Dis.arff", "../workspace/results/testing_Dis.arff")
#print weka.parseLevel(7)



